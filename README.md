# uusic (cs349 final project)

Uusic aims to create a music reccomendation system using machine-learning technqiues.

Music reccomendation systems, we found, are pretty hard to get right. There a lot of factors that go into what makes a song good, thus it is hard to predict what songs a user will like. Generally, song preference is informed by a user's past listening history, which was the basis for our approach.

So how can we create a reccomendation system that answers the question:
```
Given that a user's listening history can be represented as a set of tuples (song, rating), how can we generate a list of N songs that the user will like?
```

The input parameters and output parameters of this system make it hard to use traditional machine learning techniques directly. We found two ways to approach this problem:
* An `embedding-based` approach, where we use a neural network to learn a low-dimensional representation of songs and users, and use this representation to predict song ratings. A user's listening history can be formed into a vector within this low-dimensional space, and we can use this vector to predict the user's rating for a song using a KNN-like approach.
* A `reinforcement learning` approach, where we use a neural network to learn a policy that generates a list of N songs that the user will like. The network is trained using a reward signal that is based on the user's listening history.

For the sake of this project, we implemented both approaches and compared their performance.

## Testing Methodology
In order to test the performance of our models, we manually created a dataset of `personas` that represent different types of users. Each persona has a listening history, which is a set of tuples (song, rating), and a list of songs that we hand-labeled as songs that we think the user will like and dislike.

This dataset was pretty small, as only the 3 of us were able to create personas, hence we did not use this to train our models. Instead, for each persona, we compared each model's reccomendations to the list of songs that we hand-labeled as songs that the user will like. We then calculated the precision, recall, and F1 score of the model's reccomendations. In this context, we define:
* True Positive: A song that the model reccomended that we also hand-labeled as a song that the user will like
* False Positive: A song that the model reccomended that we hand-labeled as a song that the user will not like
* False Negative: A song that the model did not reccomend that we hand-labeled as a song that the user will like
* True Negative: A song that the model did not reccomend that we hand-labeled as a song that the user will not like

Each persona constitutes:
* A listening history of 10 songs
* A list of 10 songs that the user will like
* A list of 10 songs that the user will not like

We have 50 personas in total. In order to create our personas, we created a simple web app that allows users to rate songs and then generates a persona based on the user's ratings. We then used this web app to generate personas for each of us. Luckily, in our dataset, we had a `similarity` column, which made this process way easier, allowing us to trivially sort data by similarity.

We also programmatically generated personas to do testing, which was based off of a purely algorithmic approach. We hoped to see if there was any noticeable difference in performance between personas that were generated by humans and personas that were generated by an algorithm -- is there any inherent bias in our personas vs. personas that are generated by an algorithm?

This algorithmic approach was based on the following assumptions:
* A user's listening history is a set of tuples (song, rating)
* Users tend to like songs that are more popular
* Users tend to like songs that are more similar to songs that they have rated highly
* Users tend to like songs that were released around the same time as songs that they have rated highly
* Users tend to like songs that have similar tags to songs that they have rated highly
* Users dislike songs that have different tags to songs that they have rated highly
* Users dislike songs that are not similar to songs that they have rated highly

A user's learning history for this algoirthmic approach was generated by randomly selecting a song from the dataset, and assigning it a random weight (0.7-1.0). Then, we used the above assumptions to generate a list of songs that the user will like, with a random rating, updating the user's listening history as we go. We then used this listening history to generate a list of songs that the user will not like, after generating 10 songs in the user's history.

## Embedding-based Approach
The embedding-based approach uses a neural network to learn a low-dimensional representation of songs and users. The network is trained using a triplet loss function, where the network is trained to minimize the distance between a user's listening history and the songs that the user has rated highly, and maximize the distance between a user's listening history and the songs that the user has rated poorly.

The error function for the network is defined as:
```
error = max(0, margin + distance(user, positive) - distance(user, negative))
```
where `distance` is the euclidean distance between the user's listening history and the song, and `margin` is a hyperparameter that defines the minimum distance between the user's listening history and the positive song, and the maximum distance between the user's listening history and the negative song.

The network is trained using the Adam optimizer, with a learning rate of 0.001, and a batch size of 32. The network is trained for 100 epochs.

**Why not use the raw data to embed? Why do we bother with a neural network?**
The raw data in this neural network contains information that is non-trivial to extract. For example, a song's similarity to the other songs in the dataset is encoded into the song's features, which is based off of `lastfm`'s user data. This information is non-trivial to extract, and thus we use a neural network to learn a low-dimensional representation of the songs and users, which can be used to predict song ratings.

Instead, we would like to have some mechanism that can learn some non-trivial representation of a song, based off of the song's apparent features, like artist, genre, duration, danceability, etc. This is where the neural network comes in -- it can learn a low-dimensional representation of the song that groups similar songs together, and can be used to predict song ratings. 

With this approach, we can feed new songs into the network, dismissing the need to retrain the network every time we want to add a new song to the dataset. Instead, we simply add new songs to our vector space, and our KNN-like approach will work as expected. Additionally, this acts a level of optimization for our KNN-like apprpoach, as calculating norms in a low-dimensional space is much faster than calculating norms in a high-dimensional space.

## Raw Data Approach
The raw data approach uses a KNN-like approach to predict song ratings. It is the exact same as the embedding-based approach, except that we use the raw data to predict song ratings, instead of using a neural network to learn a low-dimensional representation of the songs and users.


## Setup

**General Setup**

1. Create a virtual environment
```bash
python -m venv venv
```

2. Activate the virtual environment
```bash
source venv/bin/activate
```

3. Install the required packages
```bash
pip install -r requirements.txt
```

4. Download the required datasets from the Google Drive link. Only Northwestern Email addresses will be able to access the link: https://drive.google.com/drive/folders/1o83d9g5NIRqc78eKce4gRyNRELDnIRhg?usp=drive_link

5. Unzip the datasets and place them in the `data` folder. Please do not change the folder structure, as the code is written to read the datasets from the `data` folder.


**Running the webserver**
To run the webserver, run the following command:
```bash
./runweb.sh
```

You can also use the `-setup` flag, which will setup the python virtual environment and install the required packages for you:
```bash
./runweb.sh -setup
```

Once you have the webserver running, you can access the web app at `http://localhost:5000/`.
